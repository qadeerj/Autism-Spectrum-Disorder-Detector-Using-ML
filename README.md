# Autism Spectrum Disorder Detection Using ABIDE

This project provides a full pipeline for detecting Autism Spectrum Disorder (ASD) using the ABIDE dataset, including preprocessing, model training, and a web-based frontend for predictions.

---

## ğŸ“ Directory Structure

```
Autism Spectrum Disorder Using ABIDE/
â”œâ”€â”€ DataSet/                  # Contains ABIDE Preprocess dataset splits
â”‚   â”œâ”€â”€ dataset_splits_fMRI.zip
â”‚   â””â”€â”€ dataset_splits_sMRI.zip
â”œâ”€â”€ Pre-processing-code/      # Scripts for data preprocessing
â”‚   â”œâ”€â”€ Extract.py
â”‚   â”œâ”€â”€ Preprocess.py
â”‚   â”œâ”€â”€ split.py
â”‚   â””â”€â”€ filtered_abide_1.csv
â”œâ”€â”€ Model-Training-code/      # Model training and evaluation scripts
â”‚   â”œâ”€â”€ BackBone01.py
â”‚   â”œâ”€â”€ BackBone02.py
â”‚   â”œâ”€â”€ Evl-B1.py
â”‚   â”œâ”€â”€ Evl-B2.py
â”‚   â”œâ”€â”€ Evl-Fusion.py
â”‚   â”œâ”€â”€ Fusion.py
â”‚   â””â”€â”€ Complete_Project.ipynb
â”œâ”€â”€ Model Weights/            # Pretrained model weights
â”‚   â”œâ”€â”€ best_fmri_expert.pth
â”‚   â”œâ”€â”€ best_fusion_model.pth
â”‚   â””â”€â”€ best_smri_expert.pth
â”œâ”€â”€ Web app/ # Web frontend (Flask)
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ results/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ requirements.txt          # Python dependencies
â””â”€â”€ README.md                 # Project documentation
```

---

## ğŸš€ Getting Started

### 1. Clone the Repository
```bash
git clone <repo-url>
cd "Autism Spectrum Disorder Using ABIDE"
```

### 2. Set Up Python Environment
It is recommended to use a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

---

## ğŸ§¹ Data Preprocessing
All preprocessing scripts are in `Pre-processing-code/`.

1. **Extract Features:**
   - Run `Extract.py` to extract Selected Images from the raw ABIDE data.
2. **Preprocess Data:**
   - Run `Preprocess.py` to clean and prepare the data for training.
3. **Split Data:**
   - Use `split.py` to split the data into training, validation, and test sets.

> **Note:** Make sure the dataset files are present in the `DataSet/` directory.

---

## ğŸ‹ï¸ Model Training
All model training and evaluation scripts are in `Model-Training-code/`.

- `BackBone01.py`, `BackBone02.py`: Backbone model architectures.
- `Fusion.py`: Model fusion logic.
- `Evl-B1.py`, `Evl-B2.py`, `Evl-Fusion.py`: Evaluation scripts for different models.
- `Complete_Project.ipynb`: Jupyter notebook for end-to-end workflow.

**To train a model:**
```bash
python Model-Training-code/BackBone01.py
# and
python Model-Training-code/BackBone02.py
# and
python Model-Training-code/Fusion.py
```

> **Tip:** Update the scripts as needed for your data paths and parameters.

---

## ğŸ§  Model Weights
Pretrained weights are stored in `Model Weights/`. You can use these directly for inference or continue training.

---

## ğŸŒ Running the Frontend (Flask App)
The web frontend is in `Web app/` and is built with Flask.

1. Navigate to the frontend directory:
   ```bash
   cd Web app/
   ```
2. Run the Flask app:
   ```bash
   python app.py
   ```
3. Open your browser and go to `http://127.0.0.1:5000/`

---

## ğŸ“ Notes & Troubleshooting
- Ensure all required Python packages are installed (see `requirements.txt`).
- Place your dataset files in the correct folders as described above.
- If you encounter errors, check file paths and Python version compatibility.
- For GPU acceleration, ensure you have the correct version of PyTorch installed for your CUDA version.

---

## ğŸ¤ Contributing
Pull requests are welcome! For major changes, please open an issue first to discuss what you would like to change.

## ğŸ¤ Team
1. Muhammad Qadeer
2. Alyan Umair 
3. Muhammad Shayan
4. Gulraiz Khan 
5. Fiza Abull Razzaq (Supervisor)
